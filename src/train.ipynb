{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries \n",
    "\n",
    "import torch \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from model import UNET\n",
    "import yaml\n",
    "\n",
    "#Import Utility Functions \n",
    "from utils import (\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    get_dataloaders,\n",
    "    check_accuracy_binary_classification,\n",
    "    save_predictions_as_imgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Parameters\n",
    "\n",
    "with open('configs/config.yaml' , 'r') as f: \n",
    "    config=yaml.safe_load(f)\n",
    "\n",
    "if config['train']['device'] == 'cuda':  # Confirm if cuda is available incase cuda is selected\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "else: \n",
    "    DEVICE ='cpu'\n",
    "\n",
    "print(f\"==> Using Device :{DEVICE}\")\n",
    "\n",
    "#model parameters\n",
    "IN_CHANNELS = config['model']['in_channels']\n",
    "OUT_CHANNELS = config['model']['out_channels']\n",
    "\n",
    "#Training hyperparameters\n",
    "BATCH_SIZE = config['train']['batch_size']\n",
    "NUM_EPOCHS = config['train']['num_epochs']\n",
    "LEARNING_RATE = float(config['train']['learning_rate'])\n",
    "\n",
    "#Dataloader parameters\n",
    "PIN_MEMORY = config['dataloader']['pin_memory']\n",
    "NUM_WORKERS = config['dataloader']['num_workers']\n",
    "\n",
    "#Dataset Parameters\n",
    "TRAIN_IMG_DIR = config['dataset']['train_img_dir']\n",
    "TRAIN_MASK_DIR = config['dataset']['train_mask_dir']\n",
    "VAL_IMG_DIR = config['dataset']['val_img_dir']\n",
    "VAL_MASK_DIR = config['dataset']['val_mask_dir']\n",
    "\n",
    "#Training Transforms Parameters (Data Augmentation)\n",
    "IMAGE_HEIGHT = config['train_transform']['resize']['image_height'] \n",
    "IMAGE_WIDTH =  config['train_transform']['resize']['image_width']\n",
    "ROTATE_LIMIT = config['train_transform']['rotate']['limit']\n",
    "ROTATE_PROB = config['train_transform']['rotate']['p']\n",
    "HORIZONTAL_FLIP_PROB = config['train_transform']['horizontal_flip']['p']\n",
    "VERTICAL_FLIP_PROB = config['train_transform']['vertical_flip']['p']\n",
    "NORMALIZE_CHANNEL_MEAN = config['train_transform']['normalize']['channel_mean']\n",
    "NORMALIZE_CHANNEL_STD = config['train_transform']['normalize']['channel_std']\n",
    "NORMALIZE_MAX_PIX_VALUE = config['train_transform']['normalize']['max_pixel_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( loader , model, optimizer , loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx , (input_data , target_labels) in enumerate(loop):\n",
    "        input_data = input_data.to(device= DEVICE)\n",
    "        target_labels = target_labels.float().unsqueeze(1).to(device=DEVICE)  # to match the tensor shape of input data\n",
    "\n",
    "        #Forward Pass\n",
    "        with torch.cuda.amp.autocast(): # To enable Automatic Mixed Precision (amp) feature \n",
    "            predictions=model(input_data)\n",
    "            loss = loss_fn(predictions, target_labels)\n",
    "\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())  # adds additional loss stats to display at the end of the tqdm bar\n",
    "\n",
    "        # Empty the GPU cache after each epoch\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Image augmentations on training data\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=ROTATE_LIMIT, p=ROTATE_PROB),\n",
    "        A.HorizontalFlip(p=HORIZONTAL_FLIP_PROB),\n",
    "        A.VerticalFlip(p=VERTICAL_FLIP_PROB),\n",
    "        A.Normalize(\n",
    "            mean=[NORMALIZE_CHANNEL_MEAN, NORMALIZE_CHANNEL_MEAN, NORMALIZE_CHANNEL_MEAN],\n",
    "            std=[NORMALIZE_CHANNEL_STD, NORMALIZE_CHANNEL_STD, NORMALIZE_CHANNEL_STD],\n",
    "            max_pixel_value=NORMALIZE_MAX_PIX_VALUE,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "#Setup image augmentations on validation data\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(\n",
    "            mean=[NORMALIZE_CHANNEL_MEAN, NORMALIZE_CHANNEL_MEAN, NORMALIZE_CHANNEL_MEAN],\n",
    "            std=[NORMALIZE_CHANNEL_STD, NORMALIZE_CHANNEL_STD, NORMALIZE_CHANNEL_STD],\n",
    "            max_pixel_value=NORMALIZE_MAX_PIX_VALUE,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create instance of UNET model class \n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE) \n",
    "\n",
    "#Setup Loss Function\n",
    "if OUT_CHANNELS == 1: \n",
    "    loss_fn = nn.BCEWithLogitsLoss() #  Here we are going with BCE(Binary Cross Entropy) with logits loss as we are doing binary classification of pixels. \n",
    "                                    #  Also nn.BCEWithLogitsLoss is more stable than nn.BCEloss\n",
    "else: \n",
    "    loss_fn = nn.CrossEntropyLoss() # You can shift to CrossEntropy loss if you want multiclass segmentation.\n",
    "\n",
    "\n",
    "# Setup Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Setup ADAM optimizer\n",
    "\n",
    "# Setup Dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    TRAIN_IMG_DIR,\n",
    "    TRAIN_MASK_DIR,\n",
    "    VAL_IMG_DIR,\n",
    "    VAL_MASK_DIR,\n",
    "    BATCH_SIZE,\n",
    "    train_transform,\n",
    "    val_transforms,\n",
    "    NUM_WORKERS,\n",
    "    PIN_MEMORY\n",
    ")\n",
    "\n",
    "#Setup Scaler to optimize compute efficiency in training loops by dynamically adjusting the scale of the gradient during backward pass\n",
    "# This is done to avoid the problem of gradient overflow or underflow.\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Empty the GPU cache before training starts\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    train(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\":optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    # check accuracy\n",
    "    check_accuracy_binary_classification(val_loader, model, device=DEVICE)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
